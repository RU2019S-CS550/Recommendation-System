{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#movie profile part\n",
    "def getMovieTag(row):\n",
    "\tuIdx, mIdx, tag, time = row\n",
    "\treturn ((mIdx, tag.lower()), 1)\n",
    "\n",
    "def count(x, y):\n",
    "\treturn (x + y)\n",
    "\n",
    "def movieTag2Tag(line):\n",
    "\t(mIdx, tag), count = line\n",
    "\treturn (tag, 1)\n",
    "\n",
    "def movieTag2Movie(line):\n",
    "\t(mIdx, tag), count = line\n",
    "\treturn (mIdx, (tag, count))\n",
    "\n",
    "class IDFScore(object):\n",
    "\tdef __init__(self, tagCount, N):\n",
    "\t\tself.tagCount = dict(tagCount)\n",
    "\t\tself.N = N\n",
    "\t\tself.tagList = sorted(self.tagCount.keys()) #the col index\n",
    "\n",
    "\tdef getTFIDF(self, line):\n",
    "\t\tmIdx, tagFrq = line\n",
    "\t\tmaxFrq = max(tagFrq, key = lambda x: x[1])[1]\n",
    "\n",
    "\t\ttagFrq = dict(tagFrq)\n",
    "\t\tTFIDF = []\n",
    "\t\tfor tag in self.tagList:\n",
    "\t\t\tif tag in tagFrq:\n",
    "\t\t\t\tIDF = math.log(self.N / self.tagCount[tag], 2)\n",
    "\t\t\t\tTF = tagFrq[tag] / maxFrq\n",
    "\t\t\t\tTFIDF.append(TF * IDF)\n",
    "\t\t\telse:\n",
    "\t\t\t\tTFIDF.append(0.)\n",
    "\t\treturn [mIdx, TFIDF]\n",
    "\n",
    "\n",
    "#user profile part\n",
    "def weightRate(rate, time): #TODO: a better approach to weight rates using time\n",
    "\trate = float(rate)\n",
    "\treturn rate\n",
    "\n",
    "def weightProfi(rate, profi): #TODO: a better approach to weight profiles using rate\n",
    "\tif rate <= 0:\n",
    "\t\treturn [0 for profiDim in profi]\n",
    "\telse:\n",
    "\t\treturn [rate * profiDim for profiDim in profi]\n",
    "\n",
    "def getRateLine(row):\n",
    "\tuIdx, mIdx, rate, time = row\n",
    "\twRate = weightRate(rate, time)\n",
    "\treturn (uIdx, (mIdx, wRate))\n",
    "\n",
    "def getUserRate(line):\n",
    "\tuIdx, mRate = line\n",
    "\tmIdx, rate = mRate\n",
    "\treturn (uIdx, (1, rate, rate ** 2))\n",
    "\n",
    "def sumUserRate(x, y):\n",
    "\txC, xR, xR2 = x\n",
    "\tyC, yR, yR2 = y\n",
    "\treturn (xC + yC, xR + yR, xR2 + yR2)\n",
    "\n",
    "class rateNormalizer(object):\n",
    "\tdef __init__(self, userRateCount):\n",
    "\t\tself.meanRate = dict()\n",
    "\t\tself.varRate = dict()\n",
    "\t\tfor uIdx, rateCount in userRateCount:\n",
    "\t\t\tcount, rate, rate2 = rateCount\n",
    "\t\t\tself.meanRate[uIdx] = rate / count\n",
    "\t\t\tself.varRate[uIdx] = (rate2 / count) - self.meanRate[uIdx] ** 2\n",
    "\t\tself.sqrtMeanVarRate = math.sqrt(sum(self.varRate.values()) / len(self.varRate))\n",
    "\t\treturn\n",
    "\n",
    "\tdef normalize(self, line):\n",
    "\t\tuIdx, mRate = line\n",
    "\t\tmIdx, rate = mRate\n",
    "\t\t#assume the rate is normal dist., normalize to N(0, 1)\n",
    "\t\tnRate = 0.1 + (rate - self.meanRate[uIdx]) / (math.sqrt(self.varRate[uIdx]) + self.sqrtMeanVarRate) #TODO: a better approach to avoid dividing by 0\n",
    "\t\treturn (mIdx, (uIdx, nRate))\n",
    "\n",
    "def getUserComponent(data):\n",
    "\tmIdx, UM = data\n",
    "\tmProfi, uRate = UM\n",
    "\tuIdx, rate = uRate\n",
    "\tuProfiCompo = weightProfi(rate, mProfi)\n",
    "\treturn (uIdx, uProfiCompo)\n",
    "\n",
    "def sumUserProfi(x, y):\n",
    "\treturn [x[i] + y[i] for i in range(len(x))]\n",
    "\n",
    "\n",
    "#similarity part\n",
    "def getCos(m, u):\n",
    "\tcompo = [m[i] * u[i] for i in range(len(m))]\n",
    "\treturn sum(compo)\n",
    "\n",
    "def normalize(profi):\n",
    "\tnorm2 = sum([dim ** 2 for dim in profi])\n",
    "\tnorm = math.sqrt(norm2)\n",
    "\treturn [dim / norm2 for dim in profi] #norm(profi) == 1\n",
    "\n",
    "def getProfi(row):\n",
    "\tidx = row[0]\n",
    "\tprofi = [float(profiDim) for profiDim in row[1:]]\n",
    "\tnProfi = normalize(profi)\n",
    "\treturn (idx, nProfi)\n",
    "\n",
    "def getSim(MU):\n",
    "\t(mIdx, mProfi), (uIdx, uProfi) = MU\n",
    "\tsim = getCos(mProfi, uProfi)\n",
    "\treturn (mIdx, uIdx, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsData = spark.read.csv('/user/hz333/data/project/tags.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(uIdx, mIdx, tag, time) => ((mIdx, tag), 1)\n",
    "movieTag = tagsData.rdd.map(getMovieTag)\n",
    "#((mIdx, tag), 1) => ((mIdx, tag), count)\n",
    "movieTagCount = movieTag.reduceByKey(count)\n",
    "\n",
    "#((mIdx, tag), count) => (tag, 1)\n",
    "tagCount = movieTagCount.map(movieTag2Tag)\n",
    "#(tag, 1) => (tag, count)\n",
    "tagCount = tagCount.reduceByKey(count)\n",
    "tagCount = tagCount.collect()\n",
    "\n",
    "#((mIdx, tag), count) => (mIdx, (tag, count))\n",
    "movieCount = movieTagCount.map(movieTag2Movie)\n",
    "#(mIdx, (tag, count)) => (mIdx, [(tag, count)])\n",
    "movieCount = movieCount.groupByKey()\n",
    "movieCount = movieCount.mapValues(list)\n",
    "\n",
    "IDF = IDFScore(tagCount, movieCount.count())\n",
    "\n",
    "#(mIdx, [(tag, count)]) => (mIdx, [mProfi])\n",
    "mProfi = movieCount.map(IDF.getTFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateData = spark.read.csv('/user/hz333/data/project/train.csv', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(uIdx, mIdx, rate, time) => (uIdx, (mIdx, wRate))\n",
    "rate = rateData.rdd.map(getRateLine)\n",
    "\n",
    "#(uIdx, (mIdx, rate)) => (uIdx, (1, rate, rate2))\n",
    "userRate = rate.map(getUserRate)\n",
    "#(uIdx, (1, rate, rate)) => (uIdx, (count, sumRate, sumRate2))\n",
    "userRate = userRate.reduceByKey(sumUserRate)\n",
    "\n",
    "userRate = userRate.collect()\n",
    "rateNorm = rateNormalizer(userRate)\n",
    "\n",
    "#(uIdx, (mIdx, rate)) => (mIdx, (uIdx, nRate))\n",
    "MURate = rate.map(rateNorm.normalize)\n",
    "#(mIdx, mProfi), (mIdx, (uIdx, rate)) => (mIdx, (mProfi, (uIdx, rate)))\n",
    "MUM = mProfi.join(MURate)\n",
    "\n",
    "#(mIdx, (mProfi, (uIdx, rate))) => (uIdx, [uProfiCompo])\n",
    "uProfiCompo = MUM.map(getUserComponent)\n",
    "#(uIdx, [uProfiCompo]) => (uIdx, [uProfi])\n",
    "uProfi = uProfiCompo.reduceByKey(sumUserProfi)\n",
    "uProfi = uProfi.filter(lambda x: sum(x[1]) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(mIdx, [mProfi]) => #(mIdx, [nMProfi])\n",
    "mProfi = mProfi.mapValues(normalize)\n",
    "#(uIdx, [uProfi]) => #(uIdx, [nMProfi])\n",
    "uProfi = uProfi.mapValues(normalize)\n",
    "\n",
    "#(mIdx, [mProfi]), (uIdx, [uProfi]) => ((mIdx, [mProfi]), (uIdx, [uProfi]))\n",
    "MU = mProfi.cartesian(uProfi)\n",
    "#((mIdx, [mProfi]), (uIdx, [uProfi])) => (mIdx, uIdx, sim)\n",
    "simMat = MU.map(getSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simCSV = spark.createDataFrame(simMat, samplingRatio = 1)\n",
    "simCSV.repartition(1).write.option('header', 'false').csv('/user/hz333/data/project/tagSim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simMat.take(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
